{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze notebook ga je een **sentiment analyse** doen op de reviews die bezoekers op Trip Advisor achterlieten na het bezoeken van 1 van de pretparken van Disney. Ga experimenteel na hoe je een goed voorspellend model kan bouwen om het sentiment van een review te voorspellen, puur aan de hand van de woorden (features) in de review. \n",
    "\n",
    "Je bouwt deze notebook __stap per stap op__. Voorzie volgende onderdelen in je notebook :\n",
    "\n",
    "- Stap 1 : data inlezen en voorbereiden\n",
    "- Stap 2 : NLP pipeline *(zie ook theorie)*\n",
    "- Stap 3 : Model opstellen: Experimenteer met volgende 3 methodes\n",
    "    * Gebruik de NLTK library & Vader \n",
    "    * Gebruik een Bag-of-Words approach in combinatie met een klassiek ML algoritme\n",
    "    * Gebruik een RNN model\n",
    "- Stap 4 : Conclusie\n",
    "\n",
    "Voorzie tevens in elke stap een __woordje uitleg over de keuzes__ die je maakt en de __resultaten__ die je hiermee bekomt. \n",
    "</br>Geef ook een vergelijking tussen de 3 methodes.\n",
    "\n",
    "<img src=\"img/disneyland.jpeg\" alt=\"Disneyland\"\n",
    "\ttitle=\"Disneyland\" width=\"800\" height=\"400\" />\n",
    "\n",
    "De **verbetersleutel** ziet er als volgt uit:\n",
    "\n",
    "\n",
    "|  Stap    | #punten | \n",
    "|-----------|:--------:|\n",
    "|  Stap 1: |     /1   |  \n",
    "|  Stap 2: |     /4   |  \n",
    "|  Stap 3: |        |  \n",
    "|  ---> 3.1 |     /2    |  \n",
    "|  ---> 3.2 |      /4| \n",
    "|  ---> 3.3 |      /4   |  \n",
    "| Stap 4:|     /2    |\n",
    "| Rapportering :|     /3   |  \n",
    "|      Totaal: |     /20    | \n",
    "\n",
    "\n",
    "### Praktische afspraken:\n",
    "Dit project wordt ingediend door deze notebook verder thuis af te werken en te uploaden op Toledo voor de start van je labo in **de week van maandag 10 januari 2022**\n",
    "\n",
    "#### Alvast veel succes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stap 1 : data inladen\n",
    "\n",
    "De data bestaat uit een .csv file die rechtstreeks ingeladen kan worden. De belangrijkste kolommen zijn uiteraard de _Review_text_ en de _Rating_ kolom. De ratings gaan van een waarde 1 tot 5, waarbij 5 uitstekend is (heel positieve review) en 1 een slechte review. </br>Modeleer hieruit een classificatieprobleem (je hoeft zeker geen 5 klassen te behouden, herwerk bvb naar een binaire classificatie of eventueel naar een probleem met 3 klassen (positief neutraal, negatief).\n",
    "\n",
    "Ga na of er waarden ontbreken, zo ja verwijder deze data.\n",
    "Ga na hoeveel data je per categorie hebt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stap 2 : Text Processing Pipeline\n",
    "\n",
    "Voorzie volgende stappen. Je kan hiervoor gebruik maken van de __NLTK library in Python__ (zie bv. https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk).\n",
    "\n",
    "De keuze voor vectorizatie kies je in de volgende stap, die keuze is immers afhankelijk van hoe je de uitwerking gaat doen).\n",
    "Uiteindelijk moet elke review vertaald worden naar een zin waarin volgende aanpassingen gebeuren :\n",
    "\n",
    "1. **Tokenization**: split elke review in woorden, zodat je er de volgende stappen kan op loslaten\n",
    "\n",
    "2. **Punctuation removal** : \n",
    "      je kan volgende punctuations verwijderen uit de review : \"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "      \n",
    "3. **Stopword Removal**: \n",
    "    de nltk.corpus module voorziet een lijst van stopwoorden die je kan gebruiken om te verwijderen uit de reviews:\n",
    "          \n",
    "        import nltk\n",
    "        from nltk.corpus import stopwords\n",
    "        \n",
    "    Deze moet je vooraf wel downloaden bvb via cmd line : _python -m nltk.downloader stopwords_\n",
    "        \n",
    "4. **Lower casing / negation handling**\n",
    "\n",
    "5. **Lemmatizing / Stemming** : Kies in deze stap voor Lemmatizing of Stemming. Voer beiden eens uit, kijk naar de verschillen en maak een keuze.\n",
    "    Zowel Lemmatizing als Stemming kan je via de NLTK library uitvoeren. zie bvb. https://www.geeksforgeeks.org/python-lemmatization-with-nltk/ en https://www.geeksforgeeks.org/python-stemming-words-with-nltk/.\n",
    "    Als je wordnet wil gebruiken zal je deze ook eerst moeten downloaden: \n",
    "   \n",
    "    python -m nltk downloader wordnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stap 3 : Sentiment analysis \n",
    "\n",
    "Ga na wat de kwaliteit is van Sentiment analyse op de reviews via volgende 3 technieken :\n",
    "\n",
    "1. Gebruik de ingebouwde sentiment analyzer VADER (Valence Aware Dictionary end sEntiment Reasoner) van de NLTL library (Zie ook: https://realpython.com/python-nltk-sentiment-analysis).\n",
    "\n",
    "2. Gebruik een Bag-of-Words techniek via CountVectorizer en TFIDFVectorizer. Gebruik na deze vectorizatie een klassiek classificatie-algoritme om je data te trainen en testen (Zie ook: https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/ of https://vitalflux.com/text-classification-bag-of-words-model-python-sklearn/).\n",
    "\n",
    "3. Gebruik een deep learning RNN en TensorFlow/Keras om je sentiment voorspeller te bouwen. Hieronder vind je enkele voorbeelden waaruit je inspiratie kan opdoen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspiratie files\n",
    "\n",
    "\n",
    "- Text classification with RNN : https://www.tensorflow.org/text/tutorials/text_classification_rnn\n",
    "- RNN with Keras (https://www.tensorflow.org/text/tutorials/text_classification_rnn)\n",
    "- https://www.kaggle.com/abhimanyu314/tripadvisor-rnn\n",
    "- https://www.kaggle.com/deepakvedantam/imdb-review-sentimental-analysis-with-keras\n",
    "- https://stackabuse.com/python-for-nlp-movie-sentiment-analysis-using-deep-learning-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stap 4 : Conclusie\n",
    "\n",
    "Becommentarieer je 3 gebruikte methodes en motiveer de keuzes die je gemaakt hebt. Maak een vergelijking tussen de methodes en geef aan waarom een methode volgens jou minder / beter presteert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
